{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydGI9qa2VO50",
        "outputId": "45198d44-6ab1-44bd-e9a9-fa4b4921d9a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020-2024 merged: 390 paragraphs\n",
            "2025 merged: 59 paragraphs\n",
            "\n",
            "✅ Saved:\n",
            "   Train (2020-2024): 380 paragraphs\n",
            "   Test (2025): 50 paragraphs\n",
            "\n",
            "Train class distribution (5-class):\n",
            "  Class 0 (regime -2): 92 (24.2%)\n",
            "  Class 1 (regime -1): 39 (10.3%)\n",
            "  Class 2 (regime 0): 18 (4.7%)\n",
            "  Class 3 (regime 1): 133 (35.0%)\n",
            "  Class 4 (regime 2): 98 (25.8%)\n",
            "\n",
            "Test class distribution (5-class):\n",
            "  Class 0 (regime -2): 11 (22.0%)\n",
            "  Class 1 (regime -1): 0 (0.0%)\n",
            "  Class 2 (regime 0): 0 (0.0%)\n",
            "  Class 3 (regime 1): 0 (0.0%)\n",
            "  Class 4 (regime 2): 39 (78.0%)\n",
            "\n",
            "Train class distribution (binary):\n",
            "  Class 0: 149 (39.2%)\n",
            "  Class 1: 231 (60.8%)\n",
            "\n",
            "Test class distribution (binary):\n",
            "  Class 0: 11 (22.0%)\n",
            "  Class 1: 39 (78.0%)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: CREATE COMPLETE MERGED DATASET (2020-2025)\n",
        "# ============================================================================\n",
        "\n",
        "def create_full_merged_dataset():\n",
        "    \"\"\"\n",
        "    Merge sentiment with market features using ret_regime as target\n",
        "    \"\"\"\n",
        "\n",
        "    # Load sentiment\n",
        "    sentiment = pd.read_csv('fed_sentiment_results.csv')\n",
        "\n",
        "    # Parse dates\n",
        "    def parse_date(s):\n",
        "        s = s.split('_')[0]\n",
        "        months = {'Jan': 1, 'Feb': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6,\n",
        "                  'July': 7, 'Aug': 8, 'Sept': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
        "        for m, num in months.items():\n",
        "            if s.startswith(m):\n",
        "                year = int(s.replace(m, ''))\n",
        "                return pd.Timestamp(year=year, month=num, day=1)\n",
        "        return None\n",
        "\n",
        "    sentiment['date'] = sentiment['statement_date'].apply(parse_date)\n",
        "    sentiment['year_month'] = sentiment['date'].dt.to_period('M')\n",
        "\n",
        "    # Load market features (2020-2024)\n",
        "    market = pd.read_csv('sp500_features.csv')\n",
        "    market['DATE'] = pd.to_datetime(market['DATE'])\n",
        "    market = market[market['DATE'] >= '2020-01-01'].copy()\n",
        "    market['year_month'] = market['DATE'].dt.to_period('M')\n",
        "\n",
        "    # Load 2025 buckets data\n",
        "    market_2025 = pd.read_csv('sp500_2025_buckets_and_onehot.csv')\n",
        "    market_2025['Date'] = pd.to_datetime(market_2025['Date'])\n",
        "    market_2025 = market_2025[market_2025['Date'] >= '2025-01-01'].copy()\n",
        "\n",
        "    # Map 2025 bucket to ret_regime format\n",
        "    def map_bucket_to_regime(bucket):\n",
        "        if pd.isna(bucket):\n",
        "            return np.nan\n",
        "        return bucket  # Already in -2, -1, 0, 1, 2 format\n",
        "\n",
        "    market_2025['ret_regime'] = market_2025['bucket'].apply(map_bucket_to_regime)\n",
        "    market_2025['year_month'] = market_2025['Date'].dt.to_period('M')\n",
        "\n",
        "    # Rename Date to DATE for consistency\n",
        "    market_2025 = market_2025.rename(columns={'Date': 'DATE'})\n",
        "\n",
        "    # For 2025, we only have limited features, so we'll use what's available\n",
        "    # Keep only common columns between datasets\n",
        "    common_cols = ['DATE', 'year_month', 'ret_regime']\n",
        "\n",
        "    market_2025_minimal = market_2025[common_cols].copy()\n",
        "    market_full = market[['DATE', 'year_month', 'ret_regime', 'ret_1m', 'vol_3m', 'vol_6m',\n",
        "                          'ret_1m_z', 'vol_3m_z', 'vol_6m_z',\n",
        "                          'ret_high_negative', 'ret_negative', 'ret_flat',\n",
        "                          'ret_positive', 'ret_high_positive']].copy()\n",
        "\n",
        "    # Merge sentiment with market (2020-2024 with full features)\n",
        "    merged_2020_2024 = pd.merge(\n",
        "        sentiment[sentiment['date'] < '2025-01-01'],\n",
        "        market_full,\n",
        "        on='year_month',\n",
        "        how='inner'\n",
        "    )\n",
        "\n",
        "    # Merge sentiment with 2025 (limited features)\n",
        "    merged_2025 = pd.merge(\n",
        "        sentiment[sentiment['date'] >= '2025-01-01'],\n",
        "        market_2025_minimal,\n",
        "        on='year_month',\n",
        "        how='inner'\n",
        "    )\n",
        "\n",
        "    print(\"2020-2024 merged:\", len(merged_2020_2024), \"paragraphs\")\n",
        "    print(\"2025 merged:\", len(merged_2025), \"paragraphs\")\n",
        "\n",
        "    # For 2025, fill missing market features with 0 (or we can drop them)\n",
        "    # Let's just use sentiment features for consistency\n",
        "\n",
        "    # Get next month's regime as target\n",
        "    # Sort by date\n",
        "    merged_2020_2024 = merged_2020_2024.sort_values(['DATE', 'statement_date', 'paragraph_num']).reset_index(drop=True)\n",
        "    merged_2025 = merged_2025.sort_values(['DATE', 'statement_date', 'paragraph_num']).reset_index(drop=True)\n",
        "\n",
        "    # For each statement, get next statement's regime\n",
        "    def get_next_regime(df, market_all):\n",
        "        unique_stmts = df[['statement_date', 'DATE', 'year_month']].drop_duplicates().sort_values('DATE').reset_index(drop=True)\n",
        "\n",
        "        stmt_to_next_regime = {}\n",
        "\n",
        "        for i in range(len(unique_stmts) - 1):\n",
        "            current_stmt = unique_stmts.iloc[i]\n",
        "            next_stmt = unique_stmts.iloc[i + 1]\n",
        "\n",
        "            # Get next month's regime from market data\n",
        "            next_month_data = market_all[market_all['DATE'] == next_stmt['DATE']]\n",
        "\n",
        "            if len(next_month_data) > 0:\n",
        "                next_regime = next_month_data.iloc[0]['ret_regime']\n",
        "                stmt_to_next_regime[current_stmt['statement_date']] = next_regime\n",
        "\n",
        "        df['target_regime'] = df['statement_date'].map(stmt_to_next_regime)\n",
        "        return df\n",
        "\n",
        "    # Combine market data\n",
        "    market_all = pd.concat([market[['DATE', 'ret_regime']], market_2025[['DATE', 'ret_regime']]], ignore_index=True)\n",
        "\n",
        "    merged_2020_2024 = get_next_regime(merged_2020_2024, market_all)\n",
        "    merged_2025 = get_next_regime(merged_2025, market_all)\n",
        "\n",
        "    # Create binary target from ret_regime\n",
        "    # ret_regime: -2,-1,0,1,2 → binary: 0 (down/flat: -2,-1,0), 1 (up: 1,2)\n",
        "    merged_2020_2024['target_binary'] = (merged_2020_2024['target_regime'] > 0).astype(float)\n",
        "    merged_2025['target_binary'] = (merged_2025['target_regime'] > 0).astype(float)\n",
        "\n",
        "    # Map ret_regime to 5-class (0,1,2,3,4)\n",
        "    def map_regime_to_class(regime):\n",
        "        if pd.isna(regime):\n",
        "            return np.nan\n",
        "        regime_map = {-2.0: 0, -1.0: 1, 0.0: 2, 1.0: 3, 2.0: 4}\n",
        "        return regime_map.get(regime, np.nan)\n",
        "\n",
        "    merged_2020_2024['target_5class'] = merged_2020_2024['target_regime'].apply(map_regime_to_class)\n",
        "    merged_2025['target_5class'] = merged_2025['target_regime'].apply(map_regime_to_class)\n",
        "\n",
        "    # Remove rows without target\n",
        "    merged_2020_2024 = merged_2020_2024[merged_2020_2024['target_5class'].notna()].copy()\n",
        "    merged_2025 = merged_2025[merged_2025['target_5class'].notna()].copy()\n",
        "\n",
        "    merged_2020_2024['target_5class'] = merged_2020_2024['target_5class'].astype(int)\n",
        "    merged_2025['target_5class'] = merged_2025['target_5class'].astype(int)\n",
        "    merged_2020_2024['target_binary'] = merged_2020_2024['target_binary'].astype(int)\n",
        "    merged_2025['target_binary'] = merged_2025['target_binary'].astype(int)\n",
        "\n",
        "    # Save\n",
        "    merged_2020_2024.to_csv('merged_train_2020_2024.csv', index=False)\n",
        "    merged_2025.to_csv('merged_test_2025.csv', index=False)\n",
        "\n",
        "    print(f\"\\n✅ Saved:\")\n",
        "    print(f\"   Train (2020-2024): {len(merged_2020_2024)} paragraphs\")\n",
        "    print(f\"   Test (2025): {len(merged_2025)} paragraphs\")\n",
        "\n",
        "    print(f\"\\nTrain class distribution (5-class):\")\n",
        "    for i in range(5):\n",
        "        count = (merged_2020_2024['target_5class'] == i).sum()\n",
        "        print(f\"  Class {i} (regime {[-2,-1,0,1,2][i]}): {count} ({100*count/len(merged_2020_2024):.1f}%)\")\n",
        "\n",
        "    print(f\"\\nTest class distribution (5-class):\")\n",
        "    for i in range(5):\n",
        "        count = (merged_2025['target_5class'] == i).sum()\n",
        "        print(f\"  Class {i} (regime {[-2,-1,0,1,2][i]}): {count} ({100*count/len(merged_2025):.1f}%)\")\n",
        "\n",
        "    print(f\"\\nTrain class distribution (binary):\")\n",
        "    for i in range(2):\n",
        "        count = (merged_2020_2024['target_binary'] == i).sum()\n",
        "        print(f\"  Class {i}: {count} ({100*count/len(merged_2020_2024):.1f}%)\")\n",
        "\n",
        "    print(f\"\\nTest class distribution (binary):\")\n",
        "    for i in range(2):\n",
        "        count = (merged_2025['target_binary'] == i).sum()\n",
        "        print(f\"  Class {i}: {count} ({100*count/len(merged_2025):.1f}%)\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    create_full_merged_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# ============================================================================\n",
        "# DATASET\n",
        "# ============================================================================\n",
        "\n",
        "class FedDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.FloatTensor(X)\n",
        "        self.y = torch.LongTensor(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# ============================================================================\n",
        "# MODELS\n",
        "# ============================================================================\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, n_classes):\n",
        "        super(MLP, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "class CNN1D(nn.Module):\n",
        "    def __init__(self, input_dim, n_classes):\n",
        "        super(CNN1D, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv1d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.Conv1d(64, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(32, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(32, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.squeeze(-1)\n",
        "        return self.fc(x)\n",
        "\n",
        "class AttentionMLP(nn.Module):\n",
        "    def __init__(self, input_dim, n_classes):\n",
        "        super(AttentionMLP, self).__init__()\n",
        "        self.embedding = nn.Sequential(nn.Linear(input_dim, 64), nn.ReLU())\n",
        "        self.attention = nn.Sequential(nn.Linear(64, 32), nn.Tanh(), nn.Linear(32, 1))\n",
        "        self.classifier = nn.Sequential(nn.Linear(64, 32), nn.ReLU(), nn.Dropout(0.3), nn.Linear(32, n_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        attention_weights = torch.softmax(self.attention(embedded), dim=0)\n",
        "        weighted = embedded * attention_weights\n",
        "        return self.classifier(weighted)\n",
        "\n",
        "class ResNetMLP(nn.Module):\n",
        "    def __init__(self, input_dim, n_classes):\n",
        "        super(ResNetMLP, self).__init__()\n",
        "        self.input_proj = nn.Linear(input_dim, 64)\n",
        "        self.block1 = nn.Sequential(nn.Linear(64, 64), nn.ReLU(), nn.Dropout(0.3), nn.Linear(64, 64), nn.ReLU())\n",
        "        self.block2 = nn.Sequential(nn.Linear(64, 32), nn.ReLU(), nn.Dropout(0.3), nn.Linear(32, 32), nn.ReLU())\n",
        "        self.fc = nn.Linear(32, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        x = x + self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "class AutoencoderClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, n_classes, latent_dim=8):\n",
        "        super(AutoencoderClassifier, self).__init__()\n",
        "        self.encoder = nn.Sequential(nn.Linear(input_dim, 32), nn.ReLU(), nn.Linear(32, 16), nn.ReLU(), nn.Linear(16, latent_dim))\n",
        "        self.decoder = nn.Sequential(nn.Linear(latent_dim, 16), nn.ReLU(), nn.Linear(16, 32), nn.ReLU(), nn.Linear(32, input_dim))\n",
        "        self.classifier = nn.Sequential(nn.Linear(latent_dim, 16), nn.ReLU(), nn.Dropout(0.3), nn.Linear(16, n_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        return self.classifier(encoded)\n",
        "\n",
        "# ============================================================================\n",
        "# LOAD DATA\n",
        "# ============================================================================\n",
        "\n",
        "def load_data(task='binary'):\n",
        "    \"\"\"\n",
        "    Load train (2020-2024) and test (2025) data\n",
        "    \"\"\"\n",
        "\n",
        "    train_df = pd.read_csv('merged_train_2020_2024.csv')\n",
        "    test_df = pd.read_csv('merged_test_2025.csv')\n",
        "\n",
        "    # Features - only sentiment (since 2025 doesn't have market features)\n",
        "    feature_cols = ['positive_score', 'negative_score', 'neutral_score', 'paragraph_num']\n",
        "\n",
        "    target_col = 'target_binary' if task == 'binary' else 'target_5class'\n",
        "    n_classes = 2 if task == 'binary' else 5\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"LOADING DATA - TASK: {task}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Train: {len(train_df)} paragraphs (2020-2024)\")\n",
        "    print(f\"Test: {len(test_df)} paragraphs (2025)\")\n",
        "    print(f\"Features: {feature_cols}\")\n",
        "\n",
        "    X_train = train_df[feature_cols].values\n",
        "    y_train = train_df[target_col].values\n",
        "    X_test = test_df[feature_cols].values\n",
        "    y_test = test_df[target_col].values\n",
        "\n",
        "    # Split train into train/val\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        "    )\n",
        "\n",
        "    # Scale\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val = scaler.transform(X_val)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    with open(f'{task}_scaler.pkl', 'wb') as f:\n",
        "        pickle.dump(scaler, f)\n",
        "\n",
        "    # Datasets\n",
        "    train_dataset = FedDataset(X_train, y_train)\n",
        "    val_dataset = FedDataset(X_val, y_val)\n",
        "    test_dataset = FedDataset(X_test, y_test)\n",
        "\n",
        "    # Class weights\n",
        "    class_counts = np.bincount(y_train)\n",
        "    class_weights = 1.0 / class_counts\n",
        "    class_weights = class_weights / class_weights.sum()\n",
        "    class_weights = torch.FloatTensor(class_weights)\n",
        "\n",
        "    print(f\"\\nTrain: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset, n_classes, class_weights, len(feature_cols), test_df\n",
        "\n",
        "# ============================================================================\n",
        "# TRAIN\n",
        "# ============================================================================\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, device, epochs=100, lr=0.001, model_name='Model'):\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Train\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_preds, train_labels = [], []\n",
        "\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            train_preds.extend(preds.cpu().numpy())\n",
        "            train_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        train_acc = accuracy_score(train_labels, train_preds)\n",
        "\n",
        "        # Val\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_preds, val_labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                outputs = model(X_batch)\n",
        "                loss = criterion(outputs, y_batch)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_preds.extend(preds.cpu().numpy())\n",
        "                val_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc = accuracy_score(val_labels, val_preds)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), f'{model_name}_best.pth')\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= 20:\n",
        "            print(f'Early stop at epoch {epoch+1}')\n",
        "            break\n",
        "\n",
        "        if (epoch + 1) % 20 == 0:\n",
        "            print(f'Epoch {epoch+1}: Train={train_acc:.4f}, Val={val_acc:.4f}')\n",
        "\n",
        "    print(f'Best Val Acc: {best_val_acc:.4f}')\n",
        "    return best_val_acc\n",
        "\n",
        "# ============================================================================\n",
        "# TEST\n",
        "# ============================================================================\n",
        "\n",
        "def test_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    preds, labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            _, pred = torch.max(outputs, 1)\n",
        "            preds.extend(pred.cpu().numpy())\n",
        "            labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return preds, labels, acc\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f'Device: {device}')\n",
        "\n",
        "    TASK = 'binary'  # Change to '5class' for 5-class\n",
        "\n",
        "    # Load\n",
        "    train_dataset, val_dataset, test_dataset, n_classes, class_weights, input_dim, test_df = load_data(TASK)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "\n",
        "    models_dict = {\n",
        "        'MLP': MLP,\n",
        "        'CNN1D': CNN1D,\n",
        "        'AttentionMLP': AttentionMLP,\n",
        "        'ResNetMLP': ResNetMLP,\n",
        "        'AutoencoderClassifier': AutoencoderClassifier\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # Train and test each model\n",
        "    for model_name, model_class in models_dict.items():\n",
        "        print(f'\\n{\"=\"*60}')\n",
        "        print(f'TRAINING: {model_name}')\n",
        "        print(f'{\"=\"*60}')\n",
        "\n",
        "        model = model_class(input_dim, n_classes)\n",
        "        best_val = train_model(model, train_loader, val_loader, criterion, device,\n",
        "                               epochs=100, lr=0.001, model_name=f'{TASK}_{model_name}')\n",
        "\n",
        "        # Load best and test on 2025\n",
        "        model.load_state_dict(torch.load(f'{TASK}_{model_name}_best.pth'))\n",
        "        model = model.to(device)\n",
        "\n",
        "        test_preds, test_labels, test_acc = test_model(model, test_loader, device)\n",
        "\n",
        "        print(f'\\n2025 Test Accuracy: {test_acc:.4f}')\n",
        "        print('\\nClassification Report:')\n",
        "        print(classification_report(test_labels, test_preds))\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(test_labels, test_preds)\n",
        "        plt.figure(figsize=(6, 5))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.title(f'{model_name} - 2025 Test')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.savefig(f'{TASK}_{model_name}_cm.png', dpi=150, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        results[model_name] = {\n",
        "            'val_acc': best_val,\n",
        "            'test_acc': test_acc,\n",
        "            'predictions': test_preds\n",
        "        }\n",
        "\n",
        "    # Summary\n",
        "    print('\\n' + '='*60)\n",
        "    print(f'FINAL RESULTS - {TASK.upper()}')\n",
        "    print('='*60)\n",
        "    for name, res in results.items():\n",
        "        print(f'{name:25s} Val: {res[\"val_acc\"]:.4f} | Test 2025: {res[\"test_acc\"]:.4f}')\n",
        "\n",
        "    # Baseline\n",
        "    baseline = np.bincount(test_labels).argmax()\n",
        "    baseline_acc = (test_labels == baseline).mean()\n",
        "    print(f'\\n{\"Baseline (most common)\":25s} Test 2025: {baseline_acc:.4f}')\n",
        "\n",
        "    # Save predictions\n",
        "    for name, res in results.items():\n",
        "        test_df[f'pred_{name}'] = res['predictions']\n",
        "\n",
        "    target_col = 'target_binary' if TASK == 'binary' else 'target_5class'\n",
        "    test_df.to_csv(f'{TASK}_2025_predictions.csv', index=False)\n",
        "    print(f'\\n✅ Saved: {TASK}_2025_predictions.csv')\n",
        "\n",
        "    # Download\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(f'{TASK}_2025_predictions.csv')\n",
        "        for name in results.keys():\n",
        "            files.download(f'{TASK}_{name}_best.pth')\n",
        "            files.download(f'{TASK}_{name}_cm.png')\n",
        "        files.download(f'{TASK}_scaler.pkl')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tzp4gMQCXlD7",
        "outputId": "ca6acb21-9842-44de-e81f-eb3729382e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "\n",
            "============================================================\n",
            "LOADING DATA - TASK: binary\n",
            "============================================================\n",
            "Train: 380 paragraphs (2020-2024)\n",
            "Test: 50 paragraphs (2025)\n",
            "Features: ['positive_score', 'negative_score', 'neutral_score', 'paragraph_num']\n",
            "\n",
            "Train: 304, Val: 76, Test: 50\n",
            "\n",
            "============================================================\n",
            "TRAINING: MLP\n",
            "============================================================\n",
            "Epoch 20: Train=0.5461, Val=0.6316\n",
            "Early stop at epoch 33\n",
            "Best Val Acc: 0.6447\n",
            "\n",
            "2025 Test Accuracy: 0.7000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.27      0.29        11\n",
            "           1       0.80      0.82      0.81        39\n",
            "\n",
            "    accuracy                           0.70        50\n",
            "   macro avg       0.55      0.55      0.55        50\n",
            "weighted avg       0.69      0.70      0.69        50\n",
            "\n",
            "\n",
            "============================================================\n",
            "TRAINING: CNN1D\n",
            "============================================================\n",
            "Epoch 20: Train=0.6118, Val=0.6447\n",
            "Early stop at epoch 28\n",
            "Best Val Acc: 0.6579\n",
            "\n",
            "2025 Test Accuracy: 0.8000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.09      0.17        11\n",
            "           1       0.80      1.00      0.89        39\n",
            "\n",
            "    accuracy                           0.80        50\n",
            "   macro avg       0.90      0.55      0.53        50\n",
            "weighted avg       0.84      0.80      0.73        50\n",
            "\n",
            "\n",
            "============================================================\n",
            "TRAINING: AttentionMLP\n",
            "============================================================\n",
            "Epoch 20: Train=0.5066, Val=0.5263\n",
            "Early stop at epoch 30\n",
            "Best Val Acc: 0.5526\n",
            "\n",
            "2025 Test Accuracy: 0.5600\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.55      0.35        11\n",
            "           1       0.81      0.56      0.67        39\n",
            "\n",
            "    accuracy                           0.56        50\n",
            "   macro avg       0.54      0.55      0.51        50\n",
            "weighted avg       0.69      0.56      0.60        50\n",
            "\n",
            "\n",
            "============================================================\n",
            "TRAINING: ResNetMLP\n",
            "============================================================\n",
            "Epoch 20: Train=0.6118, Val=0.6447\n",
            "Early stop at epoch 21\n",
            "Best Val Acc: 0.6447\n",
            "\n",
            "2025 Test Accuracy: 0.7200\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.27      0.30        11\n",
            "           1       0.80      0.85      0.82        39\n",
            "\n",
            "    accuracy                           0.72        50\n",
            "   macro avg       0.57      0.56      0.56        50\n",
            "weighted avg       0.70      0.72      0.71        50\n",
            "\n",
            "\n",
            "============================================================\n",
            "TRAINING: AutoencoderClassifier\n",
            "============================================================\n",
            "Epoch 20: Train=0.5757, Val=0.5921\n",
            "Early stop at epoch 26\n",
            "Best Val Acc: 0.6579\n",
            "\n",
            "2025 Test Accuracy: 0.7800\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        11\n",
            "           1       0.78      1.00      0.88        39\n",
            "\n",
            "    accuracy                           0.78        50\n",
            "   macro avg       0.39      0.50      0.44        50\n",
            "weighted avg       0.61      0.78      0.68        50\n",
            "\n",
            "\n",
            "============================================================\n",
            "FINAL RESULTS - BINARY\n",
            "============================================================\n",
            "MLP                       Val: 0.6447 | Test 2025: 0.7000\n",
            "CNN1D                     Val: 0.6579 | Test 2025: 0.8000\n",
            "AttentionMLP              Val: 0.5526 | Test 2025: 0.5600\n",
            "ResNetMLP                 Val: 0.6447 | Test 2025: 0.7200\n",
            "AutoencoderClassifier     Val: 0.6579 | Test 2025: 0.7800\n",
            "\n",
            "Baseline (most common)    Test 2025: 0.7800\n",
            "\n",
            "✅ Saved: binary_2025_predictions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_160227a3-f521-42b2-9612-4d2f8e05154d\", \"binary_2025_predictions.csv\", 29040)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6c8ce097-9bca-405e-b745-9b15bab2dc3e\", \"binary_MLP_best.pth\", 54061)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_39391c42-fd81-44a9-bb38-a4547a403167\", \"binary_MLP_cm.png\", 20825)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_004e5e16-7511-42a1-bdee-295bdb19c66c\", \"binary_CNN1D_best.pth\", 38685)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_aa7b8d8b-5c5f-469b-826f-70c7b76c7069\", \"binary_CNN1D_cm.png\", 22823)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_88a0aa76-9aaa-4fe7-bbc9-57dd68b4ed50\", \"binary_AttentionMLP_best.pth\", 23125)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f2d5caf8-61f0-4e60-9566-3ed024492931\", \"binary_AttentionMLP_cm.png\", 23987)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_af9ab39f-d217-4173-8dcb-23640cd9184e\", \"binary_ResNetMLP_best.pth\", 52603)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_290de8f2-334c-494c-ae96-7c6d8f42192c\", \"binary_ResNetMLP_cm.png\", 22114)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dd5a3ed2-4a45-4a15-be51-08bee0bf6313\", \"binary_AutoencoderClassifier_best.pth\", 14063)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bab4dca9-6a09-403d-8193-b4b60450c9b9\", \"binary_AutoencoderClassifier_cm.png\", 25839)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7bff5dba-cce3-418a-b0ed-5ba4cbf5862f\", \"binary_scaler.pkl\", 546)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# ============================================================================\n",
        "# DATASET\n",
        "# ============================================================================\n",
        "\n",
        "class FedDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.FloatTensor(X)\n",
        "        self.y = torch.LongTensor(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# ============================================================================\n",
        "# MODELS\n",
        "# ============================================================================\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, n_classes):\n",
        "        super(MLP, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "class CNN1D(nn.Module):\n",
        "    def __init__(self, input_dim, n_classes):\n",
        "        super(CNN1D, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv1d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.Conv1d(64, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(32, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(32, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.squeeze(-1)\n",
        "        return self.fc(x)\n",
        "\n",
        "class AttentionMLP(nn.Module):\n",
        "    def __init__(self, input_dim, n_classes):\n",
        "        super(AttentionMLP, self).__init__()\n",
        "        self.embedding = nn.Sequential(nn.Linear(input_dim, 64), nn.ReLU())\n",
        "        self.attention = nn.Sequential(nn.Linear(64, 32), nn.Tanh(), nn.Linear(32, 1))\n",
        "        self.classifier = nn.Sequential(nn.Linear(64, 32), nn.ReLU(), nn.Dropout(0.3), nn.Linear(32, n_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        attention_weights = torch.softmax(self.attention(embedded), dim=0)\n",
        "        weighted = embedded * attention_weights\n",
        "        return self.classifier(weighted)\n",
        "\n",
        "class ResNetMLP(nn.Module):\n",
        "    def __init__(self, input_dim, n_classes):\n",
        "        super(ResNetMLP, self).__init__()\n",
        "        self.input_proj = nn.Linear(input_dim, 64)\n",
        "        self.block1 = nn.Sequential(nn.Linear(64, 64), nn.ReLU(), nn.Dropout(0.3), nn.Linear(64, 64), nn.ReLU())\n",
        "        self.block2 = nn.Sequential(nn.Linear(64, 32), nn.ReLU(), nn.Dropout(0.3), nn.Linear(32, 32), nn.ReLU())\n",
        "        self.fc = nn.Linear(32, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        x = x + self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "class AutoencoderClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, n_classes, latent_dim=8):\n",
        "        super(AutoencoderClassifier, self).__init__()\n",
        "        self.encoder = nn.Sequential(nn.Linear(input_dim, 32), nn.ReLU(), nn.Linear(32, 16), nn.ReLU(), nn.Linear(16, latent_dim))\n",
        "        self.decoder = nn.Sequential(nn.Linear(latent_dim, 16), nn.ReLU(), nn.Linear(16, 32), nn.ReLU(), nn.Linear(32, input_dim))\n",
        "        self.classifier = nn.Sequential(nn.Linear(latent_dim, 16), nn.ReLU(), nn.Dropout(0.3), nn.Linear(16, n_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        return self.classifier(encoded)\n",
        "\n",
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, n_classes, d_model=64, nhead=4, num_layers=2, dropout=0.3):\n",
        "        super(TransformerClassifier, self).__init__()\n",
        "\n",
        "        # Project input to d_model dimension\n",
        "        self.input_projection = nn.Linear(input_dim, d_model)\n",
        "\n",
        "        # Positional encoding (learnable)\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, 1, d_model))\n",
        "\n",
        "        # Transformer encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=d_model * 4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model // 2, n_classes)\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch, input_dim)\n",
        "        x = self.input_projection(x)  # (batch, d_model)\n",
        "        x = x.unsqueeze(1)  # (batch, 1, d_model)\n",
        "        x = x + self.pos_embedding\n",
        "        x = self.dropout(x)\n",
        "        x = self.transformer_encoder(x)  # (batch, 1, d_model)\n",
        "        x = x.squeeze(1)  # (batch, d_model)\n",
        "        output = self.classifier(x)\n",
        "        return output\n",
        "\n",
        "# ============================================================================\n",
        "# LOAD DATA\n",
        "# ============================================================================\n",
        "\n",
        "def load_data(task='binary'):\n",
        "    train_df = pd.read_csv('merged_train_2020_2024.csv')\n",
        "    test_df = pd.read_csv('merged_test_2025.csv')\n",
        "\n",
        "    feature_cols = ['positive_score', 'negative_score', 'neutral_score', 'paragraph_num']\n",
        "    target_col = 'target_binary' if task == 'binary' else 'target_5class'\n",
        "    n_classes = 2 if task == 'binary' else 5\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"LOADING DATA - TASK: {task}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Train: {len(train_df)} paragraphs (2020-2024)\")\n",
        "    print(f\"Test: {len(test_df)} paragraphs (2025)\")\n",
        "\n",
        "    X_train = train_df[feature_cols].values\n",
        "    y_train = train_df[target_col].values\n",
        "    X_test = test_df[feature_cols].values\n",
        "    y_test = test_df[target_col].values\n",
        "\n",
        "    # Split train into train/val\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        "    )\n",
        "\n",
        "    # Scale\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val = scaler.transform(X_val)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    with open(f'{task}_scaler.pkl', 'wb') as f:\n",
        "        pickle.dump(scaler, f)\n",
        "\n",
        "    train_dataset = FedDataset(X_train, y_train)\n",
        "    val_dataset = FedDataset(X_val, y_val)\n",
        "    test_dataset = FedDataset(X_test, y_test)\n",
        "\n",
        "    # Class weights\n",
        "    class_counts = np.bincount(y_train)\n",
        "    class_weights = 1.0 / class_counts\n",
        "    class_weights = class_weights / class_weights.sum()\n",
        "    class_weights = torch.FloatTensor(class_weights)\n",
        "\n",
        "    print(f\"\\nTrain: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset, n_classes, class_weights, len(feature_cols), test_df\n",
        "\n",
        "# ============================================================================\n",
        "# TRAIN\n",
        "# ============================================================================\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, device, epochs=100, lr=0.001, model_name='Model'):\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Train\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_preds, train_labels = [], []\n",
        "\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping for transformer stability\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            train_preds.extend(preds.cpu().numpy())\n",
        "            train_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        train_acc = accuracy_score(train_labels, train_preds)\n",
        "\n",
        "        # Val\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_preds, val_labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                outputs = model(X_batch)\n",
        "                loss = criterion(outputs, y_batch)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_preds.extend(preds.cpu().numpy())\n",
        "                val_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc = accuracy_score(val_labels, val_preds)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), f'{model_name}_best.pth')\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= 20:\n",
        "            print(f'Early stop at epoch {epoch+1}')\n",
        "            break\n",
        "\n",
        "        if (epoch + 1) % 20 == 0:\n",
        "            print(f'Epoch {epoch+1}: Train={train_acc:.4f}, Val={val_acc:.4f}')\n",
        "\n",
        "    print(f'Best Val Acc: {best_val_acc:.4f}')\n",
        "    return best_val_acc\n",
        "\n",
        "# ============================================================================\n",
        "# TEST\n",
        "# ============================================================================\n",
        "\n",
        "def test_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    preds, labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            _, pred = torch.max(outputs, 1)\n",
        "            preds.extend(pred.cpu().numpy())\n",
        "            labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return preds, labels, acc\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f'Device: {device}')\n",
        "\n",
        "    TASK = 'binary'  # Change to '5class' for 5-class\n",
        "\n",
        "    # Load\n",
        "    train_dataset, val_dataset, test_dataset, n_classes, class_weights, input_dim, test_df = load_data(TASK)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "\n",
        "    models_dict = {\n",
        "        'MLP': MLP,\n",
        "        'CNN1D': CNN1D,\n",
        "        'AttentionMLP': AttentionMLP,\n",
        "        'ResNetMLP': ResNetMLP,\n",
        "        'AutoencoderClassifier': AutoencoderClassifier,\n",
        "        'TransformerClassifier': TransformerClassifier\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # Train and test each model\n",
        "    for model_name, model_class in models_dict.items():\n",
        "        print(f'\\n{\"=\"*60}')\n",
        "        print(f'TRAINING: {model_name}')\n",
        "        print(f'{\"=\"*60}')\n",
        "\n",
        "        model = model_class(input_dim, n_classes)\n",
        "        best_val = train_model(model, train_loader, val_loader, criterion, device,\n",
        "                               epochs=100, lr=0.001, model_name=f'{TASK}_{model_name}')\n",
        "\n",
        "        # Load best and test on 2025\n",
        "        model.load_state_dict(torch.load(f'{TASK}_{model_name}_best.pth'))\n",
        "        model = model.to(device)\n",
        "\n",
        "        test_preds, test_labels, test_acc = test_model(model, test_loader, device)\n",
        "\n",
        "        print(f'\\n2025 Test Accuracy: {test_acc:.4f}')\n",
        "        print('\\nClassification Report:')\n",
        "        print(classification_report(test_labels, test_preds))\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(test_labels, test_preds)\n",
        "        plt.figure(figsize=(6, 5))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.title(f'{model_name} - 2025 Test')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.savefig(f'{TASK}_{model_name}_cm.png', dpi=150, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        results[model_name] = {\n",
        "            'val_acc': best_val,\n",
        "            'test_acc': test_acc,\n",
        "            'predictions': test_preds\n",
        "        }\n",
        "\n",
        "    # Summary\n",
        "    print('\\n' + '='*60)\n",
        "    print(f'FINAL RESULTS - {TASK.upper()}')\n",
        "    print('='*60)\n",
        "    for name, res in results.items():\n",
        "        print(f'{name:25s} Val: {res[\"val_acc\"]:.4f} | Test 2025: {res[\"test_acc\"]:.4f}')\n",
        "\n",
        "    # Baseline\n",
        "    baseline = np.bincount(test_labels).argmax()\n",
        "    baseline_acc = (test_labels == baseline).mean()\n",
        "    print(f'\\n{\"Baseline (most common)\":25s} Test 2025: {baseline_acc:.4f}')\n",
        "\n",
        "    # Save predictions\n",
        "    for name, res in results.items():\n",
        "        test_df[f'pred_{name}'] = res['predictions']\n",
        "\n",
        "    target_col = 'target_binary' if TASK == 'binary' else 'target_5class'\n",
        "    test_df.to_csv(f'{TASK}_2025_predictions.csv', index=False)\n",
        "    print(f'\\n✅ Saved: {TASK}_2025_predictions.csv')\n",
        "\n",
        "    # Download\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(f'{TASK}_2025_predictions.csv')\n",
        "        for name in results.keys():\n",
        "            files.download(f'{TASK}_{name}_best.pth')\n",
        "            files.download(f'{TASK}_{name}_cm.png')\n",
        "        files.download(f'{TASK}_scaler.pkl')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a4gg8FVmS6vV",
        "outputId": "83dcfec1-493e-4c1d-adbd-cba64dc88fde"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "\n",
            "============================================================\n",
            "LOADING DATA - TASK: binary\n",
            "============================================================\n",
            "Train: 380 paragraphs (2020-2024)\n",
            "Test: 50 paragraphs (2025)\n",
            "\n",
            "Train: 304, Val: 76, Test: 50\n",
            "\n",
            "============================================================\n",
            "TRAINING: MLP\n",
            "============================================================\n",
            "Epoch 20: Train=0.5461, Val=0.6184\n",
            "Early stop at epoch 34\n",
            "Best Val Acc: 0.6711\n",
            "\n",
            "2025 Test Accuracy: 0.7800\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.09      0.15        11\n",
            "           1       0.79      0.97      0.87        39\n",
            "\n",
            "    accuracy                           0.78        50\n",
            "   macro avg       0.65      0.53      0.51        50\n",
            "weighted avg       0.73      0.78      0.72        50\n",
            "\n",
            "\n",
            "============================================================\n",
            "TRAINING: CNN1D\n",
            "============================================================\n",
            "Epoch 20: Train=0.6118, Val=0.6316\n",
            "Early stop at epoch 25\n",
            "Best Val Acc: 0.6711\n",
            "\n",
            "2025 Test Accuracy: 0.7800\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.09      0.15        11\n",
            "           1       0.79      0.97      0.87        39\n",
            "\n",
            "    accuracy                           0.78        50\n",
            "   macro avg       0.65      0.53      0.51        50\n",
            "weighted avg       0.73      0.78      0.72        50\n",
            "\n",
            "\n",
            "============================================================\n",
            "TRAINING: AttentionMLP\n",
            "============================================================\n",
            "Epoch 20: Train=0.6086, Val=0.6579\n",
            "Early stop at epoch 38\n",
            "Best Val Acc: 0.6842\n",
            "\n",
            "2025 Test Accuracy: 0.7000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.27      0.29        11\n",
            "           1       0.80      0.82      0.81        39\n",
            "\n",
            "    accuracy                           0.70        50\n",
            "   macro avg       0.55      0.55      0.55        50\n",
            "weighted avg       0.69      0.70      0.69        50\n",
            "\n",
            "\n",
            "============================================================\n",
            "TRAINING: ResNetMLP\n",
            "============================================================\n",
            "Epoch 20: Train=0.5855, Val=0.5658\n",
            "Epoch 40: Train=0.5954, Val=0.6447\n",
            "Early stop at epoch 46\n",
            "Best Val Acc: 0.6579\n",
            "\n",
            "2025 Test Accuracy: 0.7600\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.18      0.25        11\n",
            "           1       0.80      0.92      0.86        39\n",
            "\n",
            "    accuracy                           0.76        50\n",
            "   macro avg       0.60      0.55      0.55        50\n",
            "weighted avg       0.71      0.76      0.72        50\n",
            "\n",
            "\n",
            "============================================================\n",
            "TRAINING: AutoencoderClassifier\n",
            "============================================================\n",
            "Epoch 20: Train=0.5395, Val=0.5526\n",
            "Early stop at epoch 22\n",
            "Best Val Acc: 0.6316\n",
            "\n",
            "2025 Test Accuracy: 0.8000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.09      0.17        11\n",
            "           1       0.80      1.00      0.89        39\n",
            "\n",
            "    accuracy                           0.80        50\n",
            "   macro avg       0.90      0.55      0.53        50\n",
            "weighted avg       0.84      0.80      0.73        50\n",
            "\n",
            "\n",
            "============================================================\n",
            "TRAINING: TransformerClassifier\n",
            "============================================================\n",
            "Epoch 20: Train=0.5691, Val=0.6447\n",
            "Epoch 40: Train=0.5526, Val=0.6447\n",
            "Early stop at epoch 47\n",
            "Best Val Acc: 0.6842\n",
            "\n",
            "2025 Test Accuracy: 0.8000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.09      0.17        11\n",
            "           1       0.80      1.00      0.89        39\n",
            "\n",
            "    accuracy                           0.80        50\n",
            "   macro avg       0.90      0.55      0.53        50\n",
            "weighted avg       0.84      0.80      0.73        50\n",
            "\n",
            "\n",
            "============================================================\n",
            "FINAL RESULTS - BINARY\n",
            "============================================================\n",
            "MLP                       Val: 0.6711 | Test 2025: 0.7800\n",
            "CNN1D                     Val: 0.6711 | Test 2025: 0.7800\n",
            "AttentionMLP              Val: 0.6842 | Test 2025: 0.7000\n",
            "ResNetMLP                 Val: 0.6579 | Test 2025: 0.7600\n",
            "AutoencoderClassifier     Val: 0.6316 | Test 2025: 0.8000\n",
            "TransformerClassifier     Val: 0.6842 | Test 2025: 0.8000\n",
            "\n",
            "Baseline (most common)    Test 2025: 0.7800\n",
            "\n",
            "✅ Saved: binary_2025_predictions.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_81ef495a-1db5-41b5-a833-c0d49013374d\", \"binary_2025_predictions.csv\", 29167)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_38b95cbe-4b9b-457e-b1c3-ec1794e504f1\", \"binary_MLP_best.pth\", 54061)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5a00ed32-e173-449f-984d-779692d4e2bc\", \"binary_MLP_cm.png\", 21340)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_aae315d6-bdd4-4612-8996-0d3bff277639\", \"binary_CNN1D_best.pth\", 38685)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b633f29b-f260-4fd8-86a0-534b6dbe12eb\", \"binary_CNN1D_cm.png\", 21986)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9a6e2c7d-373e-4793-a252-a23db7c1274c\", \"binary_AttentionMLP_best.pth\", 23125)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1c3b91e8-b297-485e-98f8-469ce271fe94\", \"binary_AttentionMLP_cm.png\", 22378)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b5bafcb4-2032-41dd-a8a1-885fe7b16247\", \"binary_ResNetMLP_best.pth\", 52603)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9ab59505-34c7-4ab9-8d21-97a7334896a2\", \"binary_ResNetMLP_cm.png\", 22961)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_247acac1-f6d0-4752-981b-f0f390cc2fd2\", \"binary_AutoencoderClassifier_best.pth\", 14063)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_67a20382-f148-4c97-a4f3-9f1dff596815\", \"binary_AutoencoderClassifier_cm.png\", 25863)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b8673b38-cc53-4276-aa1e-79fb19771ec2\", \"binary_TransformerClassifier_best.pth\", 423304)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d867e535-ffef-49fa-a235-14cde4dc63b3\", \"binary_TransformerClassifier_cm.png\", 25187)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_68973416-8b92-4649-ab96-45b1bf479f64\", \"binary_scaler.pkl\", 546)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}